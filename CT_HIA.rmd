---
title: "Health Impact Assessment of Affordable Housing Development in Connecticut"
date: "`r Sys.time()`"
output:
  html_document:
    df_print: paged
---

```{r load packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(here)
library(readxl)
library(ncdf4)
library(raster)
library(tidycensus)
library(daymetr)
library(tidyr)
library(tigris)
library(FedData)
library(weathermetrics)
library(exactextractr)
library(terra)
library(stars)
library(sp)
library(humidity)
```

```{r declare functions}
# write functions

```

```{r load shapefiles for CT census tracts}
options(tigris_use_cache = TRUE)

# list of 5-year ACS variables for reference
vars_acs <- load_variables(year = 2019, dataset = "acs5", cache = TRUE)

# list of decennial Census variables for reference
vars_dec <- load_variables(year = 2020, dataset = "pl", cache = TRUE)

# get CT census tract polygon using variable for families in poverty
ct_tracts <- get_acs(state = "CT", geography = "tract", variables = "B17013_002", geometry = TRUE, year = 2019)

# get crs from census tract polygon
crs <- st_crs(ct_tracts)
```

```{r load shapefiles for CT townships}

# get township polygons
CT_townships <- county_subdivisions(state = "CT") %>% 
  filter(NAME != "County subdivisions not defined") %>% 
  dplyr::select(GEOID, NAME, geometry)

# read CT town lines
town_lines <- st_read("CT Town Lines/Town_Lines.shp")

# read CT town polygon
town_poly <- st_read("CT Vicinity Town Polygon/CT_Vicinity_Town_Polygon.shp") %>%
  filter(STATE_COD == "CT", is.na(TOWN_NAME) == FALSE) %>% 
  group_by(TOWN_NAME) %>%
  # keep only largest polygon per town (exclude small coastal islands)
  slice_max(order_by = SHAPE_Area)
```

```{r load pollutant datasets}
# read in PM2.5 daily average by census tract from EPA FAQSD
pm_tract <- read.delim(gzfile("2019_pm25_daily_average.txt.gz"), sep = ",") %>%
## include only Connecticut tracts - FIPS starting with 9
  filter(str_detect(`FIPS`, "^9")) %>% 
## include only index date - July 4, 2019
  filter(`Date` == "2019/07/04") %>% 
## format FIPS to match GEOID format used by tidycensus get_acs
  mutate(GEOID = str_pad(FIPS, 11, side = "left", pad = "0"))

# read in ozone daily 8-hour maximum by census tract from EPA FAQSD
o3_tract <- read.delim(gzfile("2019_ozone_daily_8hour_maximum.txt.gz"), sep = ",") %>%
## include only Connecticut tracts - FIPS starting with 9
  filter(str_detect(`FIPS`, "^9")) %>% 
## include only index date - July 4, 2019
  filter(`Date` == "2019/07/04") %>% 
## format FIPS to match GEOID format used by tidycensus get_acs
  mutate(GEOID = str_pad(FIPS, 11, side = "left", pad = "0"))

# read in NO2 data
no2 <- nc_open("SurfaceNO2_0.0083deg_2019.nc")

no2_lon <- ncvar_get(no2, "lon")
no2_lat <- ncvar_get(no2, "lat")
no2_surface <- ncvar_get(no2, "SurfaceNO2")
fillvalue <- ncatt_get(no2, "SurfaceNO2", "_FillValue")

nc_close(no2)

no2_surface[no2_surface == fillvalue$value] <- NA
no2_r <- raster(t(no2_surface), xmn = min(no2_lon), xmx = max(no2_lon), ymn = min(no2_lat), ymx = max(no2_lat), crs = crs) %>% 
  raster::flip(direction = 'y')

# extract raster values and join to town polygons
no2_vals <- extract(no2_r, town_poly, fun = mean, na.rm = TRUE, sp = T)
no2_town_sf <- st_as_sf(no2_vals)
```

```{r load temperature and calculate heat index, message=FALSE, warning=FALSE}

# write functions to find saturation VP 
# t>0 formula
calc_saturationVP <- function(t) exp(34.494 - (4924.99/(t + 237.1)))/(t + 105)^1.57  

# assign heat season dates (5/1 - 9/30)
heat_season <- seq.Date(as.Date("2019/5/1"), as.Date("2019/9/30"), "days") %>% 
  format("%m/%d")

# pull temp data from Daymet
download_daymet_ncss(location = c(42.05, -73.73, 40.98, -71.79), start = 2019, end = 2019, param = "tmax", path = here())

#pull vapor pressure data from Daymet
download_daymet_ncss(location = c(42.05, -73.73, 40.98, -71.79), start = 2019, end = 2019, param = "vp", path = here())

# use spatraster to adjust temp data crs (ADJUST)
tempstack <- rast("tmax_daily_2019_ncss.nc") %>% 
  project(crs(CT_townships)) %>% 
  stack() %>% 
  subset(121:273)

# check that t > 0 for every day in 5/1 - 9/30
tempstack %>% min()

# use spatraster to adjust vp data crs (ADJUST)
vpstack <- rast("vp_daily_2019_ncss.nc") %>% 
  project(crs(CT_townships)) %>% 
  stack() %>% 
  subset(121:273)

# initialize raster stacks for saturation VP and relative humidity
satvpstack <- tempstack
rhstack <- tempstack
heatindexstack <- tempstack

for(i in 1:length(tempstack[1])) {
  satvpstack[[i]] <- tempstack[[i]] %>% calc_saturationVP()
  rhstack[[i]] <- vpstack[[i]]/satvpstack[[i]]
  
  for(j in length(tempstack[[i]])) {
    heatindexstack[[i]][j] <- heat.index(t = tempstack[[i]][j], rh = rhstack[[i]][j], temperature.metric = "celsius", output.metric = "celsius", round = 2)
  }
}

# use exactextractr to average heat index over townships
heatindex_town <- map(1:153, ~ exact_extract(heatindexstack[[.x]], CT_townships, "mean"))

# append to CT town shapefile
for(i in 1:length(heatindex_town)) {
  CT_townships[, 3+i] <- heatindex_town[[i]]
}

# pivot to long format
heat_town_sf <- CT_townships %>% 
  rename_with(~ heat_season[1:153], .cols = 4:156) %>% 
  pivot_longer(cols = 4:156, names_to = "date", values_to = "heatindex")

```

```{r join pollutant data to shapefile}
ct_tracts <- ct_tracts %>% 
## join PM2.5 data
  left_join(., pm_tract, by = "GEOID") %>% 
## join ozone data
  left_join(., o3_tract, by = "GEOID")
```

```{r load affordable housing dataset}
# read housing data from CT Open Data
housing_town <- read.csv("Affordable_Housing_by_Town_2011-2022.csv") %>% 
  filter(Year == 2019) %>% 
  mutate(at_least_10 = cut(Percent.Affordable, breaks = c(0,9.99999,100),
  labels = c("No", "Yes"))) %>% 
  rename("TOWN_NAME" = "Town") %>% 
  # calculate new units needed to reach 10% affordable (0 if already >= 10%)
  mutate(new_units = case_when(Percent.Affordable >= 10 ~ 0, Percent.Affordable < 10 ~ (1-(Percent.Affordable/10))*X2010.Census.Units/9)) %>% 
  mutate(new_units = ceiling(new_units))

```

```{r load all-cause mortality incidence rates}
# read county-level all-cause mortality rates from CDC WONDER
allcause <- read.delim("Underlying Cause of Death, 2018-2021, Single Race_STATE.txt", sep = "\t")[1:2,-1]

allcause_race <- read.delim("Underlying Cause of Death, 1999-2020_RACE.txt", sep = "\t")[1:5,-1]

allcause_race_county <- read.delim("Underlying Cause of Death, 1999-2020_COUNTY_RACE.txt", sep = "\t")[1:33, -1]

allcause_race_county_ethn <- read.delim("Underlying Cause of Death, 1999-2020_COUNTY_RACE_ETHNICITY.txt", sep = "\t")[1:96, -1]
```

```{r load population data and clean population variables}
# list ACS variables with income brackets by race/ethnicity
incomes_vars <- c("B19001B", "B19001D", "B19001H", "B19001I")

race_eth <- c("black_nh", "asian", "white_nh", "hispanic")

# merge maximum incomes for each bracket with variable suffixes 
variable <- c("002", "003", "004", "005", "006", "007", "008", "009", "010", "011", "012", "013", "014", "015", "016", "017")

max_income <- c(9999, 14999, 19999, 24999, 29999, 34999, 39999, 44999, 49999, 59999, 74999, 99999, 124999, 149999, 199999, 200000)

income_brackets <- data.frame(variable, max_income)

# get population by race and race by ethnicity in each town
eth_by_race <- get_decennial(geography = "county subdivision", state = "CT", variables = c("P1_004N",  "P2_006N"), year = 2020, output = "wide") %>% 
  mutate(black_nh_pct = P2_006N/P1_004N)

# pull low-income limits by town
AMI_limits <- read_excel(here("Section8-FY19.xlsx")) %>% 
  filter(state_name == "Connecticut") %>% 
  dplyr::select(GEOID = fips2010, TOWN_NAME = county_town_name, limit = l80_4) %>% 
  # clean town name
  mutate(TOWN_NAME = str_sub(TOWN_NAME, 1, nchar(TOWN_NAME) - 5))

# get households in each income bracket by town for each race/ethnicity group (wide table format)
incomes_race <- map(incomes_vars, ~get_acs(geography = "county subdivision", state = "CT", table = .x, year = 2019, output = "tidy")) %>% 
  data.frame() %>%
  dplyr::select(GEOID, TOWN_NAME = NAME, variable, black = estimate, asian = estimate.1, white_nh = estimate.2, hispanic = estimate.3) %>%
  ## estimate non-Hispanic Black population using race by ethnicity per town
  left_join(eth_by_race, by = "GEOID") %>% 
  mutate(black_nh = round(black*black_nh_pct, 0)) %>% 
  filter(!str_detect(TOWN_NAME, "County subdivisions not defined")) %>% 
  mutate(TOWN_NAME = sub(" town.*", "", TOWN_NAME)) %>% 
  mutate(variable = sub(".*_", "", variable)) %>% 
  dplyr::select(GEOID, TOWN_NAME, variable, black_nh, white_nh, asian, hispanic)

# merge township data
low_income <- incomes_race %>% 
  left_join(AMI_limits, by = c("GEOID", "TOWN_NAME")) %>% 
  # inner join to filter out "001" variable (total)
  inner_join(income_brackets, by = "variable") %>%
  # make table long
  pivot_longer(cols = black_nh:hispanic, names_to = "race_ethnicity")

head(low_income)

low_income_pop <- low_income %>%
  # replace estimates above income limit with 0
  mutate(value_li = case_when(max_income <= limit ~ value, max_income > limit ~ 0)) %>% 
  group_by(TOWN_NAME, race_ethnicity) %>% 
  # sum total low-income households in each race/ethnicity variable by town
  summarize(pop_pre = sum(value_li))


head(low_income_pop)
```

```{r join housing and population data to town shapefile}
town_polygon <- town_poly %>% 
  # join housing data by town - using inner join to exclude area of Long Island Sound
  inner_join(housing_town, by = "TOWN_NAME")

# join population with low income for each race/ethnicity by town
town_polygon_list <- map(race_eth, ~ left_join(town_polygon, filter(low_income_pop, race_ethnicity == .x), by = "TOWN_NAME"))

# bind shapefiles by race/ethnicity
town_polygon_sf <- bind_rows(town_polygon_list) %>% 
  filter(is.na(race_ethnicity) == FALSE)
```

```{r average tract-level PM2.5 and ozone by township}
# using spreadsheet from 2010 census tract to town conversion tool from CT Data Collaborative: https://tract2town.ctdata.org/
tract_town <- read.csv("Census_Tracts_with_Town_Names__2010_.csv") %>% 
## join families by tract to towns by tract
  mutate(GEOID = str_pad(GEOID, 11, side = "left", pad = "0")) %>% 
  dplyr::select(GEOID, TOWN_NAME = Town) %>% 
## clean rows - delete undefined township, for now keeping rows with no exposure data (East Lyme, Wolcott)
  filter(TOWN_NAME != "County subdivisions not defined")

## clean rows - assign tracts with multiple towns and 0 families to one town
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "East Granby, Windsor Locks, Suffield"] <- "East Granby"
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Groton, Ledyard"] <- "Groton"
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Norwalk, Darien, Greenwich, Stamford, Westport"] <- "Norwalk"

## assigning Union township to only tract containing Union
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Stafford, Union"] <- "Union" 

## splitting "Canaan, Norfolk" tract among both towns since both are only found in this tract
tract_town <- tract_town %>% bind_rows(slice(., which(tract_town$TOWN_NAME == "Canaan, Norfolk"))) 
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Canaan, Norfolk"] <- "Canaan"
tract_town$TOWN_NAME[nrow(tract_town)] <- "Norfolk"

# summarize mean PM2.5 and standard deviation of tract-level estimates by town
pm_town <- tract_town %>%
  right_join(pm_tract, by = "GEOID") %>%
  group_by(`TOWN_NAME`) %>% 
  summarize(pm_mean = mean(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `Standard Deviation (ug/m3)` = sd(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `Min` = min(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `Max` = max(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `IQR (ug/m3)` = IQR(`pm25_daily_average.ug.m3.`, na.rm = TRUE))

# summarize mean and standard deviation of tract-level ozone estimates by town
o3_town <- tract_town %>%
  right_join(o3_tract, by = "GEOID") %>%
  group_by(`TOWN_NAME`) %>% 
  summarize(o3_mean = mean(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `Standard Deviation (ppb)` = sd(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `Min O3` = min(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `Max O3` = max(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `IQR (ppb)` = IQR(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE)) 

# join to town polygon
pm_town_sf <- town_poly %>% 
  left_join(pm_town, by = "TOWN_NAME")

o3_town_sf <- town_poly %>% 
  left_join(o3_town, by = "TOWN_NAME")

# summarize mean NO2 gridded estimates by town
no2_town <- no2_town_sf %>%
  group_by(TOWN_NAME) %>% 
  slice_max(order_by = SHAPE_Area) %>% 
  summarize(no2_mean = layer) %>% 
  dplyr::select(TOWN_NAME, no2_mean)

```

```{r map baseline PM2.5 and ozone by tract}
# map PM2.5 by census tract with town lines
ggplot() + geom_sf(data = ct_tracts, aes(fill = pm25_daily_average.ug.m3.)) + 
  scale_fill_viridis_c(option = "magma", direction = -1) + geom_sf(data = town_lines)

# map O3 by census tract with town lines
ggplot() + geom_sf(data = ct_tracts, aes(fill = ozone_daily_8hour_maximum.ppb.)) + scale_fill_viridis_c(option = "magma", direction = -1) + geom_sf(data = town_lines)
```

```{r map baseline pollution by township}
# map PM2.5 by town - July 4, 2019
ggplot() + geom_sf(data = pm_town_sf, aes(fill = pm_mean)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map ozone by town - July 4, 2019
ggplot() + geom_sf(data = o3_town_sf, aes(fill = o3_mean)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map NO2 by town - annual average, 2019
ggplot() + geom_sf(data = no2_town_sf, aes(fill = layer)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map heat index by town - July 4, 2019
ggplot() + geom_sf(data = heat_town_sf[heat_town_sf$date == "07/04",], aes(fill = heatindex)) + scale_fill_viridis_c(option = "magma", direction = -1)
```

```{r map baseline population by township}
# map low-income population by race/ethnicity per census tract
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "black_nh",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
```

```{r map baseline housing by township}
# map percent of affordable housing units by town
ggplot() + geom_sf(data = town_polygon, aes(fill = Percent.Affordable)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map 8-30g exemptions by town
ggplot() + geom_sf(data = town_polygon, aes(fill = at_least_10))
```

# Simulate movement into new housing with inverse distance weighting penalty

```{r set up weights for population movement, warning=FALSE}
#load population-weighted centroids


#find centroids for largest polygon per town
centroids <- town_poly %>%
  st_centroid() %>% 
  group_by(TOWN_NAME)

#assign weights to each pair of towns equal to inverse distance squared
  #list every town pair
weights <- data.frame(moved_from = rep(centroids$TOWN_NAME, times = nrow(centroids))) %>% 
  mutate(moved_to = rep(centroids$TOWN_NAME, times = rep(nrow(centroids), nrow(centroids)))) %>%
  #create columns for pre- and post-move town centroids
  mutate(centr_from = rep(centroids$geometry, times = nrow(centroids))) %>% 
  mutate(centr_to = rep(centroids$geometry, times = rep(nrow(centroids), nrow(centroids)))) %>% 
  #calculate distances between centroids
  mutate(distance = st_distance(centr_from, centr_to, by_element = TRUE)) %>% 
  mutate(distance = as.numeric(distance))

dist_0 <- weights %>% 
  filter(moved_from == moved_to) %>% 
  dplyr::select(moved_from, moved_to)

for(i in 1:nrow(dist_0)) {
  dist_0$replace[i] <- town_poly %>%
    filter(TOWN_NAME == dist_0$moved_from[i]) %>% 
    st_convex_hull() %>% 
    st_cast("MULTIPOINT") %>%
    st_cast("POINT") %>%
    st_distance() %>%
    #find max distance between any two points on town boundary and divide by two
    max(na.rm = TRUE)/2
}

#select columns from low_income_pop to join with weights
families_pre_town <- low_income_pop %>% 
  dplyr::select(moved_from = TOWN_NAME, race_ethnicity, pop_pre) 
dev_town <- housing_town %>% 
  dplyr::select(moved_to = TOWN_NAME, new_units)

#set seed for reproducible samples  
set.seed(99814)

#new method
weights_pre <- weights %>%
  left_join(families_pre_town, by = "moved_from") %>% 
  left_join(dev_town, by = "moved_to") %>% 
  left_join(dist_0, by = c("moved_from", "moved_to")) %>% 
  #replace zero-length distances with replacements (half of max distance w/in town)
  mutate(dist_new = if_else(distance == 0, replace, distance)) %>% 
  #group by town pre-move
  group_by(moved_from, race_ethnicity) %>% 
  #round up units to integer
  mutate(prop_units = new_units/sum(new_units)) %>%
  #take inverse of distance squared
  mutate(inv_sq = 1/dist_new^2) %>% 
  #calculate crude penalty using families (pre-move town), proportion of new units (post-move town), and inverse distance squared (town pair)
  mutate(penalty = prop_units*inv_sq) %>% 
  #turn penalty into weighted probability that sums to 1 for any given starting town
  mutate(lambda = penalty/sum(penalty)) %>% 
  ungroup()

# create new data frame of weights for post-simulation population movement
weights_post <- weights_pre %>% 
  # arrange by starting town
  arrange(moved_from) %>% 
  # create column for population moved in each town pair
  mutate(pop_moved = 0)
```

```{r simulate movement of households in each racial/ethnic group}
# create vector of race/ethnic groups present in summary data
race_eth_2 <- weights_post %>% pull(race_ethnicity) %>% unique()
# initialize list for weights and town pairs for each racial/ethnic grouping
weights_by_race <- list()

for(i in 1:length(race_eth_2)) {
  ## filter town pairs and weights for each racial/ethnic grouping
  weights_by_race[[i]] <- weights_post %>% filter(race_ethnicity == race_eth_2[i])
  ## draw iteratively using binomial distribution from pool of households by starting town
  for(j in 0:168) {
    weights_by_race[[i]]$pop_moved[169*j+1] <- rbinom(1, size = weights_by_race[[i]]$pop_pre[169*j+1], prob = weights_by_race[[i]]$lambda[169*j+1])
    for(k in 2:169) {
      weights_by_race[[i]]$pop_moved[169*j+k] <- rbinom(1, size = weights_by_race[[i]]$pop_pre[169*j+k] - sum(weights_by_race[[i]]$pop_moved[(169*j+1):(169*j+k)]), prob = weights_by_race[[i]]$lambda[169*j+k])
    }
  }
}

weights_post <- bind_rows(weights_by_race)

# view table
head(weights_post)

# check totals for consistency
## prop_units across all post-move towns within a given racial/ethnic group - should sum to 1
weights_post %>% filter(race_ethnicity == "white_nh", moved_from == "Andover") %>% pull(prop_units) %>% sum()
## lambda across all post-move towns within a given racial/ethnic group - should sum to 1
weights_post %>% filter(race_ethnicity == "asian_nh", moved_from == "New Haven") %>% pull(lambda) %>% sum()

## pre-move pop in specified race in given town, should equal baseline pop
weights_post %>% filter(race_ethnicity == "black_nh", moved_from == "New Haven") %>% pull(pop_pre) %>% first()
## baseline low-income households in specified race in specified town
low_income_pop %>% filter(race_ethnicity == "black_nh", TOWN_NAME == "New Haven") %>% pull(pop_pre)
## post-move households in specified race moved out of given town, should be no more than pre-move pop
weights_post %>% filter(race_ethnicity == "black_nh", moved_from == "New Haven") %>% pull(pop_moved) %>% sum()

## total households across all towns and race/ethnicity groups - should equal total households
a <- weights_post %>% filter(moved_to == "Waterbury") %>% pull(pop_pre) %>% sum()
a
## total baseline households across all towns and race/ethnicity groups
low_income_pop %>% pull(pop_pre) %>% sum()
## total households drawn to move or stay, should be no more than total households across all towns
b <- weights_post %>% pull(pop_moved) %>% sum()
b
## percent of total households across all towns/groups that were drawn to move or stay
b/a
## percent of total households across all towns/groups that moved
c <- weights_post %>% filter(moved_to != moved_from) %>% pull(pop_moved) %>% sum()
c/a
```

```{r summarize population movement}
#summarize families moved out by town
moved_out <- weights_post %>% 
  group_by(moved_from, race_ethnicity) %>%
  summarize(pop_pre = mean(pop_pre), pop_out = sum(pop_moved)) %>% 
  rename(TOWN_NAME = moved_from)

#summarize families moved in by town
moved_in <- weights_post %>% 
  group_by(moved_to, race_ethnicity) %>% 
  summarize(pop_in = sum(pop_moved)) %>% 
  rename(TOWN_NAME = moved_to)

#join moved_out and moved_in by town
pop_town_moved <- moved_out %>% 
  left_join(moved_in, by = c("TOWN_NAME", "race_ethnicity")) %>% 
  #subtract families moved out and add families moved in by town
  mutate(pop_post = pop_pre + pop_in - pop_out)

#join to town polygon
towns_moved <- town_polygon_sf %>% 
  left_join(pop_town_moved, by = c("TOWN_NAME", "race_ethnicity"))

# check that total families moved in and moved out match and do not exceed total population estimate
pop_town_moved %>% pull(pop_out) %>% sum()
pop_town_moved %>% pull(pop_in) %>% sum()

# check that total families pre and post match total population estimate
pop_town_moved %>% pull(pop_pre) %>% sum()
pop_town_moved %>% pull(pop_post) %>% sum()
low_income_pop %>% pull(pop_pre) %>% sum()
```

```{r summarize population movement by ethnoracial group}
white_nh_sim <- towns_moved %>% 
  filter(race_ethnicity == "white_nh")

black_nh_sim <- towns_moved %>% 
  filter(race_ethnicity == "black_nh")

total_sim <- towns_moved %>% 
  group_by(TOWN_NAME) %>% 
  summarize(all_pre = sum(pop_pre.x), all_in = sum(pop_in), all_out = sum(pop_out), all_post = sum(pop_post))

# check that total families pre and post match total population estimate
total_sim %>% pull(all_pre) %>% sum()
total_sim %>% pull(all_post) %>% sum()
low_income_pop %>% pull(pop_pre) %>% sum()
```

```{r map total population by town pre, during, and post move}
# map families by town pre-move
ggplot() + geom_sf(data = total_sim, aes(fill = all_pre)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families by town post-move
ggplot() + geom_sf(data = total_sim, aes(fill = all_post)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families moving out or staying
ggplot() + geom_sf(data = total_sim, aes(fill = all_out)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families moving in or staying
ggplot() + geom_sf(data = total_sim, aes(fill = all_in)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map families by town pre-move - Non-Hispanic Black households
ggplot() + geom_sf(data = black_nh_sim, aes(fill = pop_pre.x)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families by town post-move - Non-Hispanic Black households
ggplot() + geom_sf(data = black_nh_sim, aes(fill = pop_post)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
```

```{r define exposure to extreme heat}

# assign dose-response relationships / health impact functions for all-cause mortality
dr_pm_allcause <- 1.12 # HR per 10 μg/m3 increase, Pope et al., 2019
cl_pm <- 1.08 # lower bound, 95% CI
cu_pm <- 1.15 # upper bound, 95% CI

dr_o3_allcause <- 1.02 # HR per 10 ppb increase, Turner et al., 2016
cl_o3 <- 1.01 # lower bound, 95% CI
cu_o3 <- 1.04 # upper bound, 95% CI

dr_no2_allcause <- 1.06 # HR per 10 ppb increase, Huang et al., 2021
cl_no2 <- 1.04 # lower bound, 95% CI
cu_no2 <- 1.08 # upper bound, 95% CI

dr_heat_allcause <- 1.014 # rate ratio per 5 F increase (lag 0), Wellenius et al., 2017
cl_heat <- 1.004 # lower bound, 95% CI
cu_heat <- 1.024 # upper bound, 95% CI

```

```{r estimate change in incidence}

# estimate change in exposure and incidence
post_sim <- weights_post %>% 
  dplyr::select(TOWN_NAME = moved_from, moved_to, race_ethnicity, pop_moved) %>% 
  ## join baseline all-cause mortality rates (per 100,000, currently using statewide)
  mutate(mr_pre = allcause$Crude.Rate[1]) %>%
  # PM2.5
  ## join mean PM2.5 by town pre-move
  left_join(pm_town[,1:2], by = "TOWN_NAME") %>% 
  rename(pm_pre = pm_mean, moved_from = TOWN_NAME, TOWN_NAME = moved_to) %>% 
  ## join mean PM2.5 by town post-move
  left_join(pm_town[,1:2], by = "TOWN_NAME") %>% 
  rename(pm_post = pm_mean, moved_to = TOWN_NAME) %>% 
  ## calculate difference (post-pre) in PM2.5 exposure
  mutate(pm_diff = pm_post - pm_pre) %>% 
  ## join health impact function (PM2.5 and all-cause mortality)
  mutate(hif_pm = dr_pm_allcause, cl_pm = cl_pm, cu_pm = cu_pm) %>% 
  # O3
  ## join mean O3 by town pre-move
  rename(TOWN_NAME = moved_from) %>% 
  left_join(o3_town[,1:2], by = "TOWN_NAME") %>% 
  rename(o3_pre = o3_mean, moved_from = TOWN_NAME, TOWN_NAME = moved_to) %>% 
  ## join mean O3 by town post-move
  left_join(o3_town[,1:2], by = "TOWN_NAME") %>% 
  rename(o3_post = o3_mean, moved_to = TOWN_NAME) %>% 
  ## calculate difference (post-pre) in O3 exposure
  mutate(o3_diff = o3_post - o3_pre) %>% 
  # append health impact functions
  mutate(hif_o3 = dr_o3_allcause, cl_o3 = cl_o3, cu_o3 = cu_o3) %>% 
  # NO2
  ## join mean NO2 by town pre-move
  rename(TOWN_NAME = moved_from) %>% 
  left_join(no2_town[,1:2], by = "TOWN_NAME") %>% 
  rename(no2_pre = no2_mean, moved_from = TOWN_NAME, TOWN_NAME = moved_to) %>% 
  ## join mean NO2 by town post-move
  left_join(no2_town[,1:2], by = "TOWN_NAME") %>% 
  rename(no2_post = no2_mean, moved_to = TOWN_NAME) %>% 
  ## calculate difference (post-pre) in NO2 exposure
  mutate(no2_diff = no2_post - no2_pre) %>% 
  ## join health impact function (NO2 and all-cause mortality)
  mutate(hif_no2 = dr_no2_allcause, cl_no2 = cl_no2, cu_no2 = cu_no2) %>% 
  # Calculate deaths averted (each household assumed to have 4 individuals)
  mutate(across(c(hif_pm, cl_pm, cu_pm), ~ pop_moved/100000*4*mr_pre*(pm_diff/10)*(.x-1))) %>% 
    mutate(across(c(hif_o3, cl_o3, cu_o3), ~ pop_moved/100000*4*mr_pre*(o3_diff/10)*(.x-1))) %>% 
  mutate(across(c(hif_no2, cl_no2, cu_no2), ~ pop_moved/100000*4*mr_pre*(no2_diff/10)*(.x-1))) 

post_heat <- weights_post %>% 
  dplyr::select(NAME = moved_from, moved_to, race_ethnicity, pop_moved) %>% 
  # join pre-move heat index by town for each day
  left_join(CT_townships, by = "NAME") %>% 
  rename_with(~ heat_season[1:153], .cols = V4:V156) %>% 
  pivot_longer(cols = `05/01`:`09/30`, names_to = "date", values_to = "heatindex_pre") %>% 
  rename(moved_from = NAME, NAME = moved_to) %>% 
  # join post-move heat index by town and day
  left_join(heat_town_sf, by = c("NAME", "date")) %>% 
  rename(moved_to = NAME) %>% 
  # convert pre/post heat index to Fahrenheit
  mutate(heatindex_pre = heatindex_pre*9/5+32, heatindex = heatindex*9/5+32) %>% 
  mutate(heatindex = if_else(heatindex_pre >= 75 & heatindex < 75, 75, heatindex)) %>% 
  mutate(fahr_diff = if_else(heatindex_pre < 75 & heatindex < 75, 0, (heatindex - heatindex_pre))) %>% 
  # join baseline all-cause mortality rates (per 100,000, currently using statewide)
  mutate(mr_pre = allcause$Crude.Rate[1]) %>%
  mutate(hif_heat = dr_heat_allcause, cl_heat = cl_heat, cu_heat = cu_heat) %>% 
  mutate(across(c(hif_heat, cl_heat, cu_heat), ~ pop_moved/100000*4*mr_pre*(fahr_diff/5)*(.x-1))) %>% 
  group_by(moved_from, moved_to, race_ethnicity) %>% 
  summarize(hif_heat = sum(hif_heat), cl_heat = sum(cl_heat), cu_heat = sum(cu_heat), pop_moved = first(pop_moved))
  
# summarize deaths averted by ethnoracial group

averted_by_race <- post_sim %>%
  left_join(post_heat, by = c("moved_to", "moved_from", "race_ethnicity")) %>% 
  group_by(race_ethnicity) %>% 
  summarize(across(c(hif_pm, cl_pm, cu_pm, hif_o3, cl_o3, cu_o3, hif_no2, cl_no2, cu_no2, hif_heat, cl_heat, cu_heat), ~ round(-sum(.x), 1)))

averted_totals <- averted_by_race %>% 
  ungroup() %>% 
  summarize(across(hif_pm:cu_heat, ~ sum(.x)))

#check pre-move vs. post-move cumulative exposure (sum across all families drawn)
## PM2.5
pre_exp_pm <- post_sim %>% mutate(exp = pop_moved*pm_pre) %>% pull(exp) %>% sum()
post_exp_pm <- post_sim %>% mutate(exp = pop_moved*pm_post) %>% pull(exp) %>% sum()
post_exp_pm - pre_exp_pm # should be negative if exposure decreased
## O3
pre_exp_o3 <- post_sim %>% mutate(exp = pop_moved*o3_pre) %>% pull(exp) %>% sum()
post_exp_o3 <- post_sim %>% mutate(exp = pop_moved*o3_post) %>% pull(exp) %>% sum()
post_exp_o3 - pre_exp_o3 # should be negative if exposure decreased
## NO2
pre_exp_no2 <- post_sim %>% mutate(exp = pop_moved*no2_pre) %>% pull(exp) %>% sum()
post_exp_no2 <- post_sim %>% mutate(exp = pop_moved*no2_post) %>% pull(exp) %>% sum()
post_exp_no2 - pre_exp_no2 # should be negative if exposure decreased
## Heat
pre_exp_heat <- post_heat %>% mutate(exp = pop_moved*heatindex_pre) %>% pull(exp) %>% sum()
post_exp_heat <- post_heat %>% mutate(exp = pop_moved*heatindex) %>% pull(exp) %>% sum()
post_exp_heat - pre_exp_heat # should be negative if exposure decreased

```

```{r estimate population attributable fractions}
# observed cases = baseline deaths
# expected cases = counterfactual, deaths post-simulation; observed - expected = deaths averted post-simulation
## total across all racial/ethnic groups
observed <- allcause$Crude.Rate[1]*sum(low_income_pop$pop_pre)/100000*4
observed

# Population Attributable Fraction = (observed - expected)/observed
## PM2.5
paf_pm <- averted_pm/observed
## O3
paf_o3 <- averted_o3/observed
## NO2
paf_no2 <- averted_no2/observed
## Heat
paf_heat <- averted_heat/observed

# Population Attributable Fraction? = (prevalence of exposure among cases)*(1 - 1/RRadj)
# paf_pm_pre <- (1)*(1 - 1/dr_pm_allcause) # need to replace hazard ratio with hazard? - how to estimate?

# Attributable Fraction = 

```


```{r}

```

