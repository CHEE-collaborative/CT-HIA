---
title: "Health Impact Assessment of Affordable Housing Development in Connecticut"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
---

```{r load packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(here)
library(readxl)
library(ncdf4)
library(raster)
#library(rgeos)
#library(rgdal)
library(tidycensus)
library(daymetr)
library(tidyr)
```

```{r load shapefiles for CT census tracts}
options(tigris_use_cache = TRUE)

# list of 5-year ACS variables for reference
vars_acs <- load_variables(year = 2019, dataset = "acs5", cache = TRUE)
# list of decennial Census variables for reference
vars_dec <- load_variables(year = 2020, dataset = "pl", cache = TRUE)

# get CT census tract polygon using variable for families in poverty
ct_tracts <- get_acs(state = "CT", geography = "tract", variables = "B17013_002", geometry = TRUE, year = 2019)

# get crs from census tract polygon
crs <- st_crs(ct_tracts)
```

```{r load shapefiles for CT townships}
# read CT town lines
town_lines <- st_read("CT Town Lines/Town_Lines.shp")

# read CT town polygon
town_poly <- st_read("CT Vicinity Town Polygon/CT_Vicinity_Town_Polygon.shp") %>%
  filter(STATE_COD == "CT", is.na(TOWN_NAME) == FALSE) %>% 
  group_by(TOWN_NAME) %>%
  # keep only largest polygon per town (exclude small coastal islands)
  slice_max(order_by = SHAPE_Area)
```

```{r load pollutant datasets}
# read in PM2.5 daily average by census tract from EPA FAQSD
pm_tract <- read.delim(gzfile("2019_pm25_daily_average.txt.gz"), sep = ",") %>%
## include only Connecticut tracts - FIPS starting with 9
  filter(str_detect(`FIPS`, "^9")) %>% 
## include only index date - July 4, 2019
  filter(`Date` == "2019/07/04") %>% 
## format FIPS to match GEOID format used by tidycensus get_acs
  mutate(GEOID = str_pad(FIPS, 11, side = "left", pad = "0"))

# read in ozone daily 8-hour maximum by census tract from EPA FAQSD
o3_tract <- read.delim(gzfile("2019_ozone_daily_8hour_maximum.txt.gz"), sep = ",") %>%
## include only Connecticut tracts - FIPS starting with 9
  filter(str_detect(`FIPS`, "^9")) %>% 
## include only index date - July 4, 2019
  filter(`Date` == "2019/07/04") %>% 
## format FIPS to match GEOID format used by tidycensus get_acs
  mutate(GEOID = str_pad(FIPS, 11, side = "left", pad = "0"))

# read in NO2 data
no2 <- nc_open("SurfaceNO2_0.0083deg_2019.nc")

no2_lon <- ncvar_get(no2, "lon")
no2_lat <- ncvar_get(no2, "lat")
no2_surface <- ncvar_get(no2, "SurfaceNO2")
fillvalue <- ncatt_get(no2, "SurfaceNO2", "_FillValue")

nc_close(no2)

no2_surface[no2_surface == fillvalue$value] <- NA
no2_r <- raster(t(no2_surface), xmn = min(no2_lon), xmx = max(no2_lon), ymn = min(no2_lat), ymx = max(no2_lat), crs = crs) %>% 
  raster::flip(direction = 'y')

# extract raster values and join to town polygons
no2_vals <- extract(no2_r, town_poly, fun = mean, na.rm = TRUE, sp = T)
no2_town_sf <- st_as_sf(no2_vals)

# read in temperature data
```

```{r join pollutant data to shapefile}
ct_tracts <- ct_tracts %>% 
## join PM2.5 data
  left_join(., pm_tract, by = "GEOID") %>% 
## join ozone data
  left_join(., o3_tract, by = "GEOID")
```

```{r load affordable housing dataset}
# read housing data from CT Open Data
housing_town <- read.csv("Affordable_Housing_by_Town_2011-2022.csv") %>% 
  filter(`Year` == 2019) %>% 
  mutate(`At least 10%?` = cut(`Percent.Affordable`, breaks = c(0,9.99999,100),
  labels = c("No", "Yes"))) %>% 
  rename("TOWN_NAME" = "Town") %>% 
  mutate(`Units Needed` = ceiling((1-(`Percent.Affordable`/10))*`X2010.Census.Units`*(1/9)))

# set units needed to 0 for towns already at or above 10% threshold
housing_town$`Units Needed`[housing_town$`At least 10%` == "Yes"] = 0
```

```{r load all-cause mortality incidence rates}
# read county-level all-cause mortality rates from CDC WONDER
allcause <- read.delim("Underlying Cause of Death, 2018-2021, Single Race_STATE.txt", sep = "\t")[1:2,-1]

allcause_race <- read.delim("Underlying Cause of Death, 1999-2020_RACE.txt", sep = "\t")[1:5,-1]

allcause_race_county <- read.delim("Underlying Cause of Death, 1999-2020_COUNTY_RACE.txt", sep = "\t")[1:33, -1]

allcause_race_county_ethn <- read.delim("Underlying Cause of Death, 1999-2020_COUNTY_RACE_ETHNICITY.txt", sep = "\t")[1:96, -1]
```

```{r load population data and clean population variables}
# list ACS variables with income brackets by race/ethnicity
incomes_vars <- c("B19001A", "B19001B", "B19001C", "B19001D", "B19001E", "B19001F", "B19001G", "B19001H", "B19001I")

race_eth <- c("white", "black", "ai_an", "asian", "nh_pi", "other_race", "multiracial", "white_nh", "hispanic")

# merge maximum incomes for each bracket with variable suffixes 
variable <- c("002", "003", "004", "005", "006", "007", "008", "009", "010", "011", "012", "013", "014", "015", "016", "017")

max_income <- c(9999, 14999, 19999, 24999, 29999, 34999, 39999, 44999, 49999, 59999, 74999, 99999, 124999, 149999, 199999, 200000)

income_brackets <- data.frame(variable, max_income)

# get population by race in each town
race <- get_decennial(geography = "county subdivision", state = "CT", table = "P1", year = 2020, output = "tidy")
# get population by Hispanic or Latino ethnicity by race in each town
eth_by_race <- get_decennial(geography = "county subdivision", state = "CT", table = "P2", year = 2020, output = "tidy") %>% 
  pivot_wider(names_from = variable, values_from = value) %>% 
  mutate(black_nh_pct = P2_006N/P2_003N) %>% 
  mutate(ai_an_nh_pct = P2_007N/P2_003N) %>% 
  mutate(asian_nh_pct = P2_008N/P2_003N) %>% 
  mutate(nh_pi_nh_pct = P2_009N/P2_003N) %>%
  mutate(other_race_nh_pct = P2_010N/P2_003N) %>% 
  mutate(multiracial_nh_pct = P2_011N/P2_003N) %>% 
  dplyr::select(TOWN_NAME = NAME, black_nh_pct:multiracial_nh_pct)

# pull low-income limits by town
AMI_limits <- read_excel(here("Section8-FY19.xlsx")) %>% 
  filter(state_name == "Connecticut") %>% 
  dplyr::select(GEOID = fips2010, TOWN_NAME = county_town_name, limit = l80_4) %>% 
  # clean town name
  mutate(TOWN_NAME = str_sub(TOWN_NAME, 1, nchar(TOWN_NAME) - 5))

# get households in each income bracket by town for each race/ethnicity group (wide table format)
incomes_race <- map(incomes_vars, ~get_acs(geography = "county subdivision", state = "CT", table = .x, year = 2019, output = "tidy")) %>% 
  data.frame() %>%
  dplyr::select(GEOID, TOWN_NAME = NAME, variable, estimate, estimate.1, estimate.2, estimate.3, estimate.4, estimate.5, estimate.6, estimate.7, estimate.8) %>% 
  rename(white = estimate, black = estimate.1, ai_an = estimate.2, asian = estimate.3, nh_pi = estimate.4, other_race = estimate.5, multiracial = estimate.6, white_nh = estimate.7, hispanic = estimate.8) %>% 
  mutate(nonhispanic = rowSums(across(c(white, black, ai_an, asian, nh_pi, other_race, multiracial))) - hispanic) %>% 
  ## estimate ethnoracial-specific population using race by ethnicity per town
  left_join(eth_by_race, by = "TOWN_NAME") %>% 
  mutate(white_h = white - white_nh) %>%
  mutate(black_nh = hispanic*black_nh_pct) %>% 
  mutate(black_h = black - black_nh) %>% 
  mutate(ai_an_nh = hispanic*ai_an_nh_pct) %>% 
  mutate(ai_an_h = ai_an - ai_an_nh) %>% 
  mutate(asian_nh = hispanic*asian_nh_pct) %>% 
  mutate(asian_h = asian - asian_nh) %>% 
  mutate(other_race_nh = hispanic*other_race_nh_pct) %>% 
  mutate(other_race_h = other_race - other_race_nh) %>% 
  mutate(multiracial_nh = hispanic*multiracial_nh_pct) %>% 
  mutate(multiracial_h = multiracial - multiracial_nh) %>% 
  filter(!str_detect(TOWN_NAME, "County subdivisions not defined")) %>% 
  mutate(TOWN_NAME = sub(" town.*", "", TOWN_NAME)) %>% 
  mutate(variable = sub(".*_", "", variable))

# merge township data
low_income <- incomes_race %>% 
  left_join(AMI_limits, by = c("GEOID", "TOWN_NAME")) %>% 
  # inner join to filter out "001" variable (total)
  inner_join(income_brackets, by = "variable") %>% 
  # make table long
  pivot_longer(cols = white:hispanic, names_to = "race_ethnicity")

head(low_income)

low_income_pop <- low_income %>%
  # replace estimates above income limit with 0
  mutate(value_li = case_when(max_income <= limit ~ value, max_income > limit ~ 0)) %>% 
  group_by(TOWN_NAME, race_ethnicity) %>% 
  # sum total low-income households in each race/ethnicity variable by town
  summarize(pop_pre = sum(value_li)) %>% 
  dplyr::select(TOWN_NAME, race_ethnicity, pop_pre)

head(low_income_pop)
```

```{r join housing and population data to town shapefile}
town_polygon <- town_poly %>% 
  # join housing data by town - using inner join to exclude area of Long Island Sound
  inner_join(housing_town, by = "TOWN_NAME")

# join population with low income for each race/ethnicity by town
town_polygon_list <- map(race_eth, ~ left_join(town_polygon, filter(low_income_pop, race_ethnicity == .x), by = "TOWN_NAME"))

# bind shapefiles by race/ethnicity
town_polygon_sf <- bind_rows(town_polygon_list[[1]], town_polygon_list[[2]], town_polygon_list[[3]], town_polygon_list[[4]], town_polygon_list[[5]], town_polygon_list[[6]], town_polygon_list[[7]], town_polygon_list[[8]], town_polygon_list[[9]])
```

```{r average tract-level PM2.5 and ozone by township}
# using spreadsheet from 2010 census tract to town conversion tool from CT Data Collaborative: https://tract2town.ctdata.org/
tract_town <- read.csv("Census_Tracts_with_Town_Names__2010_.csv") %>% 
## join families by tract to towns by tract
  mutate(GEOID = str_pad(GEOID, 11, side = "left", pad = "0")) %>% 
  dplyr::select(GEOID, TOWN_NAME = Town) %>% 
## clean rows - delete undefined township, for now keeping rows with no exposure data (East Lyme, Wolcott)
  filter(TOWN_NAME != "County subdivisions not defined")

## clean rows - assign tracts with multiple towns and 0 families to one town
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "East Granby, Windsor Locks, Suffield"] <- "East Granby"
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Groton, Ledyard"] <- "Groton"
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Norwalk, Darien, Greenwich, Stamford, Westport"] <- "Norwalk"

## assigning Union township to only tract containing Union
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Stafford, Union"] <- "Union" 

## splitting "Canaan, Norfolk" tract among both towns since both are only found in this tract
tract_town <- tract_town %>% bind_rows(slice(., which(tract_town$TOWN_NAME == "Canaan, Norfolk"))) 
tract_town$TOWN_NAME[tract_town$TOWN_NAME == "Canaan, Norfolk"] <- "Canaan"
tract_town$TOWN_NAME[nrow(tract_town)] <- "Norfolk"

# summarize mean PM2.5 and standard deviation of tract-level estimates by town
pm_town <- tract_town %>%
  right_join(pm_tract, by = "GEOID") %>%
  group_by(`TOWN_NAME`) %>% 
  summarize(pm_mean = mean(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `Standard Deviation (ug/m3)` = sd(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `Min` = min(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `Max` = max(`pm25_daily_average.ug.m3.`, na.rm = TRUE), `IQR (ug/m3)` = IQR(`pm25_daily_average.ug.m3.`, na.rm = TRUE))

# summarize mean and standard deviation of tract-level ozone estimates by town
o3_town <- tract_town %>%
  right_join(o3_tract, by = "GEOID") %>%
  group_by(`TOWN_NAME`) %>% 
  summarize(o3_mean = mean(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `Standard Deviation (ppb)` = sd(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `Min O3` = min(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `Max O3` = max(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE), `IQR (ppb)` = IQR(`ozone_daily_8hour_maximum.ppb.`, na.rm = TRUE)) 

# summarize mean NO2 gridded estimates by town (largest polygon)
no2_town <- no2_town_sf %>%
  group_by(TOWN_NAME) %>% 
  slice_max(order_by = SHAPE_Area) %>% 
  summarize(no2_mean = layer) %>% 
  dplyr::select(TOWN_NAME, no2_mean)

# join to town polygon
pm_town_sf <- town_poly %>% 
  left_join(pm_town, by = "TOWN_NAME")

o3_town_sf <- town_poly %>% 
  left_join(o3_town, by = "TOWN_NAME")
```

```{r map tract-level PM2.5 and ozone exposure contrast within townships}
# map PM2.5 standard deviation by town
ggplot() + geom_sf(data = pm_town_sf, aes(fill = `Standard Deviation (ug/m3)`)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map PM2.5 IQR by town
ggplot() + geom_sf(data = pm_town_sf, aes(fill = `IQR (ug/m3)`)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map ozone standard deviation by town
ggplot() + geom_sf(data = o3_town_sf, aes(fill = `Standard Deviation (ppb)`)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map ozone IQR by town
ggplot() + geom_sf(data = o3_town_sf, aes(fill = `IQR (ppb)`)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
```

```{r map tract-level baseline PM2.5 and ozone}
# map PM2.5 by census tract with town lines
ggplot() + geom_sf(data = ct_tracts, aes(fill = pm25_daily_average.ug.m3.)) + 
  scale_fill_viridis_c(option = "magma", direction = -1) + geom_sf(data = town_lines)

# map O3 by census tract with town lines
ggplot() + geom_sf(data = ct_tracts, aes(fill = ozone_daily_8hour_maximum.ppb.)) + 
  scale_fill_viridis_c(option = "magma", direction = -1) + geom_sf(data = town_lines)
```

```{r map baseline pollution by township}
# map PM2.5 by town
ggplot() + geom_sf(data = pm_town_sf, aes(fill = pm_mean)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

#map ozone by town
ggplot() + geom_sf(data = o3_town_sf, aes(fill = o3_mean)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

#map NO2 by town
ggplot() + geom_sf(data = no2_town_sf, aes(fill = layer)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

#map heat index by town

```

```{r map baseline population by township}
# map low-income population by census tract - White race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "white",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Black race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "black",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - AI/AN race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "ai_an",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Asian race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "asian",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Native Hawaiian/Other Pacific Islander race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "nh_pi",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Some Other Race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "other_race",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Multiracial
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "multiracial",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Non-Hispanic White race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "white_nh",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
# map low-income population by census tract - Hispanic/Latino ethnicity, any race
ggplot() + geom_sf(data = town_polygon_sf[town_polygon_sf$race_ethnicity == "hispanic",], aes(fill = pop_pre)) + scale_fill_viridis_c(option = "magma", direction = -1)
```

```{r map baseline housing by township}
# map percent of affordable housing units by town
ggplot() + geom_sf(data = town_polygon, aes(fill = `Percent.Affordable`)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)

# map 8-30g exemptions by town
ggplot() + geom_sf(data = town_polygon, aes(fill = `At least 10%?`))
```

# Simulate movement into new housing with inverse distance weighting penalty

```{r set up weights for population movement, warning=FALSE}
#load population-weighted centroids


#find centroids for largest polygon per town
centroids <- town_poly %>%
  st_centroid() %>% 
  group_by(TOWN_NAME)

#assign weights to each pair of towns equal to inverse distance squared
  #list every town pair
weights <- data.frame(moved_from = rep(centroids$TOWN_NAME, times = nrow(centroids))) %>% 
  mutate(moved_to = rep(centroids$TOWN_NAME, times = rep(nrow(centroids), nrow(centroids)))) %>%
  #create columns for pre- and post-move town centroids
  mutate(centr_from = rep(centroids$geometry, times = nrow(centroids))) %>% 
  mutate(centr_to = rep(centroids$geometry, times = rep(nrow(centroids), nrow(centroids)))) %>% 
  #calculate distances between centroids
  mutate(distance = st_distance(centr_from, centr_to, by_element = TRUE)) %>% 
  mutate(distance = as.numeric(distance))

dist_0 <- weights %>% 
  filter(moved_from == moved_to) %>% 
  dplyr::select(moved_from, moved_to)

for(i in 1:nrow(dist_0)) {
  dist_0$replace[i] <- town_poly %>% 
    group_by(TOWN_NAME) %>% 
    slice_max(order_by = SHAPE_Area) %>% 
    filter(TOWN_NAME == dist_0$moved_from[i]) %>% 
    st_convex_hull() %>% 
    st_cast("MULTIPOINT") %>%
    st_cast("POINT") %>%
    st_distance() %>%
    #find max distance between any two points on town boundary and divide by two
    max(na.rm = TRUE)/2
}

#select columns from low_income_pop to join with weights
families_pre_town <- low_income_pop %>% 
  dplyr::select(moved_from = TOWN_NAME, race_ethnicity, pop_pre) 
dev_town <- housing_town %>% 
  dplyr::select(moved_to = `TOWN_NAME`, `Units Needed`)

#set seed for reproducible samples  
set.seed(99814)

#new method
weights_pre <- weights %>%
  left_join(families_pre_town, by = "moved_from") %>% 
  left_join(dev_town, by = "moved_to") %>% 
  left_join(dist_0, by = c("moved_from", "moved_to")) %>% 
  #replace zero-length distances with replacements (half of max distance w/in town)
  mutate(dist_new = if_else(distance == 0, replace, distance)) %>% 
  #group by town pre-move
  group_by(moved_from, race_ethnicity) %>% 
  #round up units to integer
  mutate(prop_units = `Units Needed`/sum(`Units Needed`)) %>%
  #take inverse of distance squared
  mutate(inv_sq = 1/dist_new^2) %>% 
  #calculate crude penalty using families (pre-move town), proportion of new units (post-move town), and inverse distance squared (town pair)
  mutate(penalty = prop_units*inv_sq) %>% 
  #turn penalty into weighted probability that sums to 1 for any given starting town
  mutate(lambda = penalty/sum(penalty)) %>% 
  ungroup()

# create new data frame of weights for post-simulation population movement
weights_post <- weights_pre %>% 
  # arrange by starting town
  arrange(moved_from) %>% 
  # create column for population moved in each town pair
  mutate(pop_moved = 0)
```

```{r simulate movement of households in each racial/ethnic group}
# initialize list for weights and town pairs for each racial/ethnic grouping
weights_by_race <- list()

for(i in 1:length(race_eth)) {
  ## filter town pairs and weights for each racial/ethnic grouping
  weights_by_race[[i]] <- weights_post %>% filter(race_ethnicity == race_eth[i])
  ## draw iteratively from binomial distribution from pool of households by starting town
  for(j in 0:168) {
    weights_by_race[[i]]$pop_moved[169*j+1] <- rbinom(1, size = weights_by_race[[i]]$pop_pre[169*j+1], prob = weights_by_race[[i]]$lambda[169*j+1])
    for(k in 2:169) {
      weights_by_race[[i]]$pop_moved[169*j+k] <- rbinom(1, size = weights_by_race[[i]]$pop_pre[169*j+k] - sum(weights_by_race[[i]]$pop_moved[(169*j+1):(169*j+k)]), prob = weights_by_race[[i]]$lambda[169*j+k])
    }
  }
}

weights_post <- bind_rows(weights_by_race[[1]], weights_by_race[[2]], weights_by_race[[3]], weights_by_race[[4]], weights_by_race[[5]], weights_by_race[[6]], weights_by_race[[7]], weights_by_race[[8]], weights_by_race[[9]])

# view table
head(weights_post)

# check totals for consistency
## prop_units across all post-move towns within a given racial/ethnic group - should sum to 1
weights_post %>% filter(race_ethnicity == "nh_pi", moved_from == "New Haven") %>% pull(prop_units) %>% sum()
## lambda across all post-move towns within a given racial/ethnic group - should sum to 1
weights_post %>% filter(race_ethnicity == "asian", moved_from == "New Haven") %>% pull(lambda) %>% sum()

## pre-move pop in specified race in given town, should equal baseline pop
weights_post %>% filter(race_ethnicity == "black", moved_from == "New Haven") %>% pull(pop_pre) %>% first()
## baseline low-income households in specified race in specified town
low_income_pop %>% filter(race_ethnicity == "black", TOWN_NAME == "New Haven") %>% pull(pop_pre)
## post-move households in specified race moved out of given town, should be no more than pre-move pop
weights_post %>% filter(race_ethnicity == "black", moved_from == "New Haven") %>% pull(pop_moved) %>% sum

## total households across all towns and race/ethnicity groups - should equal total households
a <- weights_post %>% filter(moved_to == "Waterbury") %>% pull(pop_pre) %>% sum()
a
## total baseline households across all towns and race/ethnicity groups
low_income_pop %>% pull(pop_pre) %>% sum()
## total households drawn to move or stay in specified race, should be no more than total households across all towns
b <- weights_post %>% pull(pop_moved) %>% sum()
b
## percent of total households across all towns/groups that were drawn to move or stay
b/a*100
## percent of total households across all towns/groups that moved
c <- weights_post %>% filter(moved_to != moved_from) %>% pull(pop_moved) %>% sum()
c/a*100
```

```{r summarize population movement}
#summarize families moved out by town
moved_out <- weights_post %>% 
  group_by(moved_from, race_ethnicity) %>%
  summarize(pop_pre = mean(pop_pre), pop_out = sum(pop_moved)) %>% 
  rename(TOWN_NAME = moved_from)

#summarize families moved in by town
moved_in <- weights_post %>% 
  group_by(moved_to, race_ethnicity) %>% 
  summarize(pop_in = sum(pop_moved)) %>% 
  rename(TOWN_NAME = moved_to)

#join moved_out and moved_in by town
pop_town_moved <- moved_out %>% 
  left_join(moved_in, by = c("TOWN_NAME", "race_ethnicity")) %>% 
  #subtract families moved out and add families moved in by town
  mutate(pop_post = pop_pre + pop_in - pop_out)

#join to town polygon
towns_moved <- town_polygon_sf %>% 
  left_join(pop_town_moved, by = c("TOWN_NAME", "race_ethnicity")) %>%
  group_by(TOWN_NAME) %>% 
  mutate(all_pop_pre = sum(pop_pre.x), all_pop_in = sum(pop_in), all_pop_out = sum(pop_out), all_pop_post = sum(pop_post))

# check that total families moved in and moved out match and do not exceed total population estimate
pop_town_moved %>% pull(pop_out) %>% sum()
pop_town_moved %>% pull(pop_in) %>% sum()

# check that total families pre and post match total population estimate
pop_town_moved %>% pull(pop_pre) %>% sum()
pop_town_moved %>% pull(pop_post) %>% sum()
towns_moved %>% pull(all_pop_pre) %>% sum()/length(race_eth)
towns_moved %>% pull(all_pop_post) %>% sum()/length(race_eth)
low_income_pop %>% pull(pop_pre) %>% sum()
```

```{r map total population by town pre, during, and post move}
# map families by town pre-move
ggplot() + geom_sf(data = towns_moved, aes(fill = all_pop_pre)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families by town post-move
ggplot() + geom_sf(data = towns_moved, aes(fill = all_pop_post)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families moving out or staying
ggplot() + geom_sf(data = towns_moved, aes(fill = all_pop_out)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
# map families moving in or staying
ggplot() + geom_sf(data = towns_moved, aes(fill = all_pop_in)) + 
  scale_fill_viridis_c(option = "magma", direction = -1)
```

```{r estimate change in incidence}

#assign dose-response relationships / health impact functions for all-cause mortality
dr_pm_allcause <- 1.12 #HR per 10 μg/m3 increase, Pope et al., 2019
dr_o3_allcause <- 1.02 #HR per 10 ppb increase, Turner et al., 2016
dr_no2_allcause <- 1.06 #HR per 10 ppb increase, Huang et al., 2021
#dr_heat_allcause

##all-cause mortality and O3

##all-cause mortality and NO2

##all-cause mortality and temperature

#estimate change in exposure and incidence
post_sim <- weights_post %>% 
  dplyr::select(TOWN_NAME = moved_from, moved_to, race_ethnicity, pop_moved) %>% 
  ##join baseline all-cause mortality rates (per 100,000, currently using statewide)
  mutate(mr_pre = allcause$Crude.Rate[1]) %>%
  #PM2.5
  ##join mean PM2.5 by town pre-move
  left_join(pm_town[,1:2], by = "TOWN_NAME") %>% 
  rename(pm_pre = pm_mean, moved_from = TOWN_NAME, TOWN_NAME = moved_to) %>% 
  ##join mean PM2.5 by town post-move
  left_join(pm_town[,1:2], by = "TOWN_NAME") %>% 
  rename(pm_post = pm_mean, moved_to = TOWN_NAME) %>% 
  ##calculate difference (post-pre) in PM2.5 exposure
  mutate(pm_diff = pm_post - pm_pre) %>% 
  ##join health impact function (PM2.5 and all-cause mortality)
  mutate(hif_pm = dr_pm_allcause) %>% 
  #O3
  ##join mean O3 by town pre-move
  rename(TOWN_NAME = moved_from) %>% 
  left_join(o3_town[,1:2], by = "TOWN_NAME") %>% 
  rename(o3_pre = o3_mean, moved_from = TOWN_NAME, TOWN_NAME = moved_to) %>% 
  ##join mean O3 by town post-move
  left_join(o3_town[,1:2], by = "TOWN_NAME") %>% 
  rename(o3_post = o3_mean, moved_to = TOWN_NAME) %>% 
  ##calculate difference (post-pre) in O3 exposure
  mutate(o3_diff = o3_post - o3_pre) %>% 
  #join health impact function (O3 and all-cause mortality)
  mutate(hif_o3 = dr_o3_allcause) %>% 
  #NO2
  ##join mean NO2 by town pre-move
  rename(TOWN_NAME = moved_from) %>% 
  left_join(no2_town[,1:2], by = "TOWN_NAME") %>% 
  rename(no2_pre = no2_mean, moved_from = TOWN_NAME, TOWN_NAME = moved_to) %>% 
  ##join mean NO2 by town post-move
  left_join(no2_town[,1:2], by = "TOWN_NAME") %>% 
  rename(no2_post = no2_mean, moved_to = TOWN_NAME) %>% 
  ##calculate difference (post-pre) in NO2 exposure
  mutate(no2_diff = no2_post - no2_pre) %>% 
  ##join health impact function (NO2 and all-cause mortality)
  mutate(hif_no2 = dr_no2_allcause) %>% 
  #Calculate deaths averted
  ##calculate post-move mortality rates using health impact functions
  ###PM2.5
  mutate(mr_pm = mr_pre*hif_pm^(pm_diff/10)) %>% 
  ###O3
  mutate(mr_o3 = mr_pre*hif_o3^(o3_diff/10)) %>% 
  ###NO2
  mutate(mr_no2 = mr_pre*hif_no2^(no2_diff/10)) %>% 
  ##calculate absolute difference in mortality rates (post-pre)
  ###PM2.5
  mutate(diff_pm = mr_pm - mr_pre) %>%
  ###O3
  mutate(diff_o3 = mr_o3 - mr_pre) %>%
  ###NO2
  mutate(diff_no2 = mr_no2 - mr_pre) %>%
  ## calculate deaths averted (each household assumed to have 4 individuals)
  ### PM2.5  
  mutate(averted_pm = -diff_pm*pop_moved/100000*4) %>% 
  ### O3 
  mutate(averted_o3 = -diff_o3*pop_moved/100000*4) %>% 
  ### NO2 
  mutate(averted_no2 = -diff_no2*pop_moved/100000*4)
  
# sum total number of deaths averted
## PM2.5
averted_pm <- sum(post_sim$averted_pm)
## O3
averted_o3 <- sum(post_sim$averted_o3)
## NO2
averted_no2 <- sum(post_sim$averted_no2)

#check post vs. pre-move deaths (sum across all families drawn)
pre <- sum(post_sim$pop_moved*post_sim$mr_pre)*4/100000
post_pm <- sum(post_sim$pop_moved*post_sim$mr_pm)*4/100000
post_o3 <- sum(post_sim$pop_moved*post_sim$mr_o3)*4/100000
post_no2 <- sum(post_sim$pop_moved*post_sim$mr_no2)*4/100000
#should equal averted but negative
post_pm - pre
post_o3 - pre
post_no2 - pre
```

```{r estimate population attributable fractions}
# observed cases = baseline deaths
## total across all racial/ethnic groups
observed <- allcause$Crude.Rate[1]*sum(low_income_pop$pop_pre)/100000*4
observed
# expected cases = counterfactual, deaths post-simulation; observed - expected = deaths averted post-simulation
# Attributable fraction = (observed - expected)/observed
## PM2.5
paf_pm <- averted_pm/observed
## O3
paf_o3 <- averted_o3/observed
## NO2
paf_no2 <- averted_no2/observed
# percent of observed deaths that are attributable to exposure (vs. counterfactual)
paf_pm*100
paf_o3*100
paf_no2*100
#for continuous exposure: PAF = (∫max, xc=min P(xc)RR(xc)dxc − ∫max, xcf=min P(xcf)RR(xcf)dxcf) / (∫max, xc=min P(xc)RR(xc)dxc) from Shield et al., 2016

```




